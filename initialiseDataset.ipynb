{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1227cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download, clean and merge imdb film dataset\n",
    "\n",
    "\n",
    "#import modules, packages and libraries ~ 10mins\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as req\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import time\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "#get film datasets\n",
    "\n",
    "#set urls\n",
    "url_title_basics = 'https://datasets.imdbws.com/title.basics.tsv.gz' #film name, year, runtime, genres\n",
    "url_crew = 'https://datasets.imdbws.com/title.principals.tsv.gz' #actors, actresses, cinematographers, directors (redundant)\n",
    "url_ratings = 'https://datasets.imdbws.com/title.ratings.tsv.gz' #ratings for films (not all)\n",
    "url_names = 'https://datasets.imdbws.com/name.basics.tsv.gz' #link table for names against nconst\n",
    "url_langs = 'https://datasets.imdbws.com/title.akas.tsv.gz' #link table for names against nconst\n",
    "\n",
    "#download from url\n",
    "res_title_basics = req.get(url_title_basics).content\n",
    "res_crew = req.get(url_crew).content\n",
    "res_ratings = req.get(url_ratings).content\n",
    "res_names = req.get(url_names).content\n",
    "res_lang = req.get(url_langs).content\n",
    "\n",
    "#decompress\n",
    "title_basics_gzip = gzip.decompress(res_title_basics)\n",
    "crew_basics_gzip = gzip.decompress(res_crew)\n",
    "title_ratings_gzip = gzip.decompress(res_ratings)\n",
    "names_gzip = gzip.decompress(res_names)\n",
    "title_langs_gzip = gzip.decompress(res_lang)\n",
    "\n",
    "#read csv into dataframes\n",
    "titles = pd.read_csv(BytesIO(title_basics_gzip), delimiter='\\t',low_memory=False)\n",
    "crew = pd.read_csv(BytesIO(crew_basics_gzip), delimiter='\\t',low_memory=False)\n",
    "ratings = pd.read_csv(BytesIO(title_ratings_gzip), delimiter='\\t',low_memory=False)\n",
    "names = pd.read_csv(BytesIO(names_gzip), delimiter='\\t',low_memory=False)\n",
    "langs = pd.read_csv(BytesIO(title_langs_gzip), delimiter='\\t',low_memory=False)\n",
    "\n",
    "print('Downloaded data')\n",
    "\n",
    "\n",
    "#clean data\n",
    "\n",
    "# #filter only English-speaking regions\n",
    "desired_langs = ['en']\n",
    "filtered_langs = langs[langs['language'].isin(desired_langs)]\n",
    "tconsts_filtered_langs = filtered_langs['titleId'].tolist()\n",
    "\n",
    "desired_regions = ['CA', 'US', 'GB', 'IE', 'AU', 'NZ']\n",
    "filtered_regions = langs[langs['region'].isin(desired_regions)]\n",
    "tconsts_filtered_regions = filtered_regions['titleId'].tolist()\n",
    "\n",
    "#remove unsuitable films\n",
    "titles = titles[titles['titleType'] == 'movie']\n",
    "titles = titles[titles['genres'] != r'\\N']\n",
    "titles['isAdult'] = pd.to_numeric(titles['isAdult'], errors='coerce')\n",
    "titles = titles[titles['isAdult'] == 0 ]\n",
    "titles = titles[(titles['startYear'] >= '1955') & (titles['startYear'] != r'\\N')]\n",
    "titles = titles[(titles['tconst'].isin(tconsts_filtered_langs) & (titles['tconst'].isin(tconsts_filtered_regions)))]\n",
    "\n",
    "#get tconsts for remaining non-film rows, and remove corresponding non-film rows\n",
    "film_tconsts = titles['tconst'].tolist()\n",
    "crew = crew[crew['tconst'].isin(film_tconsts)]\n",
    "ratings = ratings[ratings['tconst'].isin(film_tconsts)]\n",
    "\n",
    "#get tconsts for remaining non-film rows\n",
    "film_tconsts = titles['tconst'].tolist()\n",
    "#remove corresponding non-film rows\n",
    "crew = crew[crew['tconst'].isin(film_tconsts)]\n",
    "ratings = ratings[ratings['tconst'].isin(film_tconsts)]\n",
    "\n",
    "#set columns to remove from dataset\n",
    "remove_from_titles = ['originalTitle', 'endYear', 'titleType', 'isAdult']\n",
    "remove_from_crew = ['ordering','job','characters']\n",
    "remove_from_ratings = ['numVotes']\n",
    "remove_from_names = ['birthYear', 'deathYear', 'primaryProfession', 'knownForTitles']\n",
    "\n",
    "titles = titles.drop(columns=remove_from_titles)\n",
    "crew = crew.drop(columns=remove_from_crew)\n",
    "ratings = ratings.drop(columns=remove_from_ratings)\n",
    "names = names.drop(columns=remove_from_names)\n",
    "\n",
    "print('Cleaned data 1')\n",
    "\n",
    "\n",
    "#merge relational tables\n",
    "\n",
    "crew_data = crew.copy()\n",
    "\n",
    "#merge crew data with names table to get respective names rather than nconst\n",
    "crew_data['nconst'] = crew_data['nconst'].str.split(', ')\n",
    "crew_data = crew_data.explode('nconst')\n",
    "crew_data = pd.merge(crew_data, names, on='nconst', how='left')\n",
    "crew_data = crew_data.pivot_table(\n",
    "    index=['tconst'],\n",
    "    columns=['category'],\n",
    "    values=['primaryName'],\n",
    "    aggfunc=lambda x: ', '.join(str(item) for item in x),\n",
    ").reset_index()\n",
    "\n",
    "#formaat and restructure columns\n",
    "crew_data.columns = [' '.join(col).strip() for col in crew_data.columns.values]\n",
    "crew_data.columns = ['tconst', 'actor', 'actress', 'archive_footage', 'archive_sound', 'cinematographer', 'composer', 'director', 'editor', 'producer', 'production_designer', 'self', 'writer']\n",
    "\n",
    "#merge datasets for one complete table\n",
    "crew_data = crew_data.drop(columns=['archive_footage','archive_sound','self', 'production_designer'])\n",
    "film_data = pd.merge(titles, ratings, on='tconst', how='left')\n",
    "film_data = pd.merge(film_data, crew_data, on='tconst', how='left')\n",
    "\n",
    "print('Merged tables')\n",
    "\n",
    "\n",
    "\n",
    "#remove data-sparse films\n",
    "\n",
    "columns_check = ['director', 'cinematographer', 'editor', 'writer', 'composer', 'producer']\n",
    "film_data = film_data[film_data[columns_check].isna().sum(axis=1) < 4]\n",
    "\n",
    "film_data= film_data.dropna(subset=['actor', 'actress'])\n",
    "film_data = film_data.dropna(subset=['runtimeMinutes'])\n",
    "film_data = film_data.dropna(subset=['averageRating'])\n",
    "film_data = film_data.dropna(subset=['genres'])\n",
    "\n",
    "#add columns for plot and poster path\n",
    "film_data['plot'] = np.nan\n",
    "film_data['poster'] = np.nan\n",
    "\n",
    "print('Cleaned data 2')\n",
    "\n",
    "\n",
    "\n",
    "film_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get film plot and poster with tmdb api ~ >2hrs\n",
    "\n",
    "\n",
    "#call api/details for each film with multiprocessing and mutlithreading\n",
    "\n",
    "\n",
    "from tmdb_calls import doBatch\n",
    "import concurrent.futures\n",
    "from multiprocessing import Manager\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    manager = Manager()\n",
    "    shared_data = manager.Namespace()\n",
    "    agg_list = []\n",
    "\n",
    "    batch_size = 1000\n",
    "    sleep_time = 3\n",
    "\n",
    "    num_batches = (len(film_data) // batch_size) + 1\n",
    "    print(f\"Total batches: {num_batches}\")\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(8) as process_executor:\n",
    "\n",
    "        for i in range(num_batches):\n",
    "\n",
    "            start_index = i * batch_size\n",
    "            end_index = (i + 1) * batch_size\n",
    "            \n",
    "            shared_data.film_data = film_data.iloc[start_index:end_index]\n",
    "\n",
    "            future = process_executor.submit(doBatch, shared_data)\n",
    "\n",
    "            concurrent.futures.wait([future])\n",
    "\n",
    "            agg_list.append(shared_data.film_data)\n",
    "\n",
    "            print(f\"{1000*(i+1)} films completed\")\n",
    "                \n",
    "    film_data = pd.concat(agg_list, ignore_index=True)\n",
    "\n",
    "\n",
    "film_data = film_data.dropna(subset=['plot'])\n",
    "\n",
    "\n",
    "print('Fetched film summaries and poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export film data to json\n",
    "\n",
    "#shuffle order\n",
    "film_data = film_data.sample(frac=1)\n",
    "result = film_data.to_json('webpage/films.json' ,orient=\"records\")\n",
    "\n",
    "print('Exported as json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
